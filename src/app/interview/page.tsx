"use client";

import { useEffect, useState } from "react";
import RecordingControls from "@/components/interview/RecordingControls";
import DeviceSettings from "@/components/interview/DeviceSettings";
import QuestionDisplay from "@/components/interview/QuestionDisplay";
import UserVideo from "@/components/interview/UserVideo";
import InterviewerView from "@/components/interview/InterviewerView";

const questionList = [
  "ìê¸°ì†Œê°œ í•´ì£¼ì„¸ìš”.",
  "ìš°ë¦¬ íšŒì‚¬ì— ì§€ì›í•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
  "ìµœê·¼ì— í–ˆë˜ í”„ë¡œì íŠ¸ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
];

export default function InterviewPage() {
  const [currentIndex, setCurrentIndex] = useState(0);
  const [questionStarted, setQuestionStarted] = useState(false);
  const [interviewPaused, setInterviewPaused] = useState(false);
  const [stream, setStream] = useState<MediaStream | null>(null);

  // ğŸ¥ ì‚¬ìš©ì ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ê°€ì ¸ì˜¤ê¸°
  useEffect(() => {
    const getStream = async () => {
      try {
        const media = await navigator.mediaDevices.getUserMedia({
          video: true,
          audio: true,
        });
        setStream(media);
        setQuestionStarted(true); // âœ… ì—¬ê¸°ì„œ ì‹œì‘!
      } catch (err) {
        alert("ì¹´ë©”ë¼/ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.");
      }
    };

    getStream();
  }, []);

  // â© ë‹¤ìŒ ì§ˆë¬¸ ì§„í–‰
  const goToNextQuestion = () => {
    if (currentIndex + 1 < questionList.length) {
      setCurrentIndex((prev) => prev + 1);
      setQuestionStarted(false);
      setTimeout(() => setQuestionStarted(true), 500);
    } else {
      alert("ë©´ì ‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!");
    }
  };

  // ğŸ“¤ ì˜ìƒ ì œì¶œ í•¸ë“¤ëŸ¬ (ìˆ˜ì •í•„ìš”!!!)
  const handleSubmit = async (blob: Blob) => {
    const formData = new FormData();
    formData.append("video", blob);
    formData.append("question", questionList[currentIndex]);

    await fetch("/api/interview/submit", {
      method: "POST",
      body: formData,
    });

    goToNextQuestion();
  };

  // ğŸ“¡ ë§ˆì´í¬/ì¹´ë©”ë¼ ìƒíƒœ ê°ì§€ ë° ì¸í„°ë·° ì •ì§€/ì¬ê°œ
  const handleDeviceToggle = (type: "camera" | "mic", isOn: boolean) => {
    if (!isOn) {
      alert(
        `âš ï¸ ${
          type === "camera" ? "ì¹´ë©”ë¼" : "ë§ˆì´í¬"
        }ê°€ êº¼ì¡ŒìŠµë‹ˆë‹¤. ì¸í„°ë·°ê°€ ì¼ì‹œ ì¤‘ì§€ë©ë‹ˆë‹¤.`,
      );
      setInterviewPaused(true);
    } else {
      const videoTrack = stream?.getVideoTracks()[0];
      const audioTrack = stream?.getAudioTracks()[0];

      if (videoTrack?.enabled && audioTrack?.enabled) {
        alert(
          "âœ… ì¹´ë©”ë¼ì™€ ë§ˆì´í¬ê°€ ëª¨ë‘ ì¼œì¡ŒìŠµë‹ˆë‹¤. ì¸í„°ë·°ë¥¼ ë‹¤ì‹œ ì‹œì‘í•©ë‹ˆë‹¤.",
        );
        setInterviewPaused(false);
        setQuestionStarted(false);
        setTimeout(() => setQuestionStarted(true), 300);
      }
    }
  };

  return (
    <div className="p-8 space-y-4">
      {/* ì§ˆë¬¸ í‘œì‹œ */}
      <QuestionDisplay
        question={questionList[currentIndex]}
        index={currentIndex}
        total={questionList.length}
      />

      <div className="flex gap-4">
        {/* ë©´ì ‘ê´€ ë”ë¯¸ */}
        <div className="flex-[3]">
          <InterviewerView />
        </div>

        {/* ìš°ì¸¡ */}
        <div className="flex-[2] flex flex-col gap-2 items-center">
          <UserVideo stream={stream} />
          <DeviceSettings stream={stream} onDeviceToggle={handleDeviceToggle} />
          {!interviewPaused ? (
            <RecordingControls
              stream={stream}
              questionStarted={questionStarted}
              onAutoSubmit={handleSubmit}
              onManualSubmit={handleSubmit}
            />
          ) : (
            <div className="text-red-500 text-sm mt-2">
              ë…¹í™”ê°€ ì¼ì‹œ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì¹´ë©”ë¼/ë§ˆì´í¬ë¥¼ ë‹¤ì‹œ ì¼œì£¼ì„¸ìš”.
            </div>
          )}
        </div>
      </div>
    </div>
  );
}
